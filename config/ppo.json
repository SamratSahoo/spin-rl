{
    "algorithm": "ppo",
    "timesteps": 4800000,
    "policy": "MultiInputPolicy",
    "model": {
        "policy_kwargs": {
            "net_arch": {
                "qf": [
                    512,
                    256,
                    128
                ],
                "pi": [
                    512,
                    256,
                    128
                ]
            }
        },
        "n_steps": 2048,
        "batch_size": 128,
        "n_epochs": 10,
        "learning_rate": 0.0003,
        "clip_range": 0.2,
        "gamma": 0.99,
        "gae_lambda": 0.95,
        "ent_coef": 0.01,
        "vf_coef": 0.5,
        "max_grad_norm": 0.5
    },
    "eval_recording_folder": "./recordings/ppo",
    "tensorboard_log": "./tensorboard/ppo",
    "train_from_checkpoint": true,
    "eval_freq": 4000,
    "model_save_folder": "./models/ppo",
    "temp_dir": "./tmp_ppo"
}